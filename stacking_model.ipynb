{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用模型集合\n",
    "\n",
    "* Resnet50\n",
    "* Inception V3\n",
    "* Xception\n",
    "* mobileNet\n",
    "\n",
    "### 使用数据增强\n",
    "\n",
    "```\n",
    "       gen = ImageDataGenerator(rotation_range=5, height_shift_range=0.05, horizontal_flip=True,\n",
    "                           shear_range=0.1, channel_shift_range=10, width_shift_range=0.1)\n",
    "```\n",
    "\n",
    "### 使用BacthNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 参考：[猫狗大战](https://github.com/ypwhs/dogs_vs_cats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预处理数据\n",
    "    由于之前已经把数据分成了dogs 文件夹和 cats 文件夹，这里就可以使用Keras中的 ImageDataGenerator 来自动处理训练数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.applications import *\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "from tqdm import *\n",
    "import h5py\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_preTrain(MODEL, image_size, lambda_func=None):\n",
    "    width = image_size[0]\n",
    "    height = image_size[1]\n",
    "    input_tensor = Input((height, width, 3))\n",
    "    x = input_tensor\n",
    "    if lambda_func:\n",
    "        x = Lambda(lambda_func)(x)\n",
    "    base_model = MODEL(input_tensor=x, weights='imagenet', include_top=False)\n",
    "    model = Model(base_model.input, GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "    gen = ImageDataGenerator(rotation_range=5, height_shift_range=0.05, horizontal_flip=True,\n",
    "                                 shear_range=0.1, channel_shift_range=10, width_shift_range=0.1)\n",
    "    \n",
    "    train_generator = gen.flow_from_directory(\"train3\", image_size, shuffle=False, \n",
    "                                              batch_size=batch_size)\n",
    "    valid_generator = gen.flow_from_directory(\"valid3\", image_size, shuffle=False, \n",
    "                                              batch_size=batch_size)\n",
    "    test_generator = gen.flow_from_directory(\"test3\", image_size, shuffle=False, \n",
    "                                             batch_size=batch_size, class_mode=None)\n",
    "\n",
    "    train = model.predict_generator(train_generator, steps=train_generator.samples//batch_size,verbose=1)\n",
    "    valid = model.predict_generator(valid_generator, steps=valid_generator.samples//batch_size,verbose=1)\n",
    "    test = model.predict_generator(test_generator, steps=test_generator.samples//batch_size,verbose=1)\n",
    "    \n",
    "    with h5py.File(\"pre_{}s.h5\".format(MODEL.__name__)) as h:\n",
    "        h.create_dataset(\"train\", data=train)\n",
    "        h.create_dataset(\"valid\", data=valid)\n",
    "        h.create_dataset(\"test\", data=test)\n",
    "        h.create_dataset(\"train_label\", data=train_generator.classes)\n",
    "        h.create_dataset(\"valid_label\", data=valid_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22500 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "2250/2250 [==============================] - 283s 126ms/step\n",
      "250/250 [==============================] - 32s 126ms/step\n",
      "1250/1250 [==============================] - 157s 126ms/step\n"
     ]
    }
   ],
   "source": [
    "write_preTrain(ResNet50, (224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22500 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "2250/2250 [==============================] - 505s 224ms/step\n",
      "250/250 [==============================] - 56s 224ms/step\n",
      "1250/1250 [==============================] - 280s 224ms/step\n"
     ]
    }
   ],
   "source": [
    "write_preTrain(Xception, (299, 299), xception.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22500 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "2250/2250 [==============================] - 420s 186ms/step\n",
      "250/250 [==============================] - 47s 189ms/step\n",
      "1250/1250 [==============================] - 230s 184ms/step\n"
     ]
    }
   ],
   "source": [
    "write_preTrain(InceptionV3, (299, 299), inception_v3.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.8/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "76398592/76391848 [==============================] - 1s 0us/step\n",
      "Found 22500 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "2250/2250 [==============================] - 782s 347ms/step\n",
      "250/250 [==============================] - 86s 345ms/step\n",
      "1250/1250 [==============================] - 431s 345ms/step\n"
     ]
    }
   ],
   "source": [
    "write_preTrain(DenseNet201, (299, 299), densenet.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22500 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "2250/2250 [==============================] - 717s 319ms/step\n",
      "250/250 [==============================] - 80s 319ms/step\n",
      "1250/1250 [==============================] - 398s 319ms/step\n"
     ]
    }
   ],
   "source": [
    "write_preTrain(InceptionResNetV2, (299, 299), inception_resnet_v2.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train = []\n",
    "X_valid = []\n",
    "X_test = []\n",
    "\n",
    "for filename in [\"pre_ResNet50s.h5\", \"pre_Xceptions.h5\", \"pre_InceptionV3s.h5\",\"pre_InceptionResNetV2s.h5\",\"pre_DenseNet201s.h5\"]:\n",
    "    with h5py.File(filename, 'r') as h:\n",
    "        X_train.append(np.array(h['train']))\n",
    "        X_valid.append(np.array(h['valid']))\n",
    "        X_test.append(np.array(h['test']))\n",
    "        y_train = np.array(h['train_label'])\n",
    "        y_valid = np.array(h['valid_label'])\n",
    "\n",
    "X_train = np.concatenate(X_train, axis=1)\n",
    "X_valid = np.concatenate(X_valid, axis=1)\n",
    "X_test = np.concatenate(X_test, axis=1)\n",
    "\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22500, 9600)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "input_tensor = Input(X_train.shape[1:])\n",
    "x = input_tensor\n",
    "#x = Dropout(0.5)(x)\n",
    "x = BatchNormalization(axis=1)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(input_tensor, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adadelta',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22500 samples, validate on 2500 samples\n",
      "Epoch 1/8\n",
      "22500/22500 [==============================] - 2s 71us/step - loss: 0.0277 - acc: 0.9906 - val_loss: 0.0248 - val_acc: 0.9932\n",
      "Epoch 2/8\n",
      "22500/22500 [==============================] - 1s 54us/step - loss: 0.0119 - acc: 0.9968 - val_loss: 0.0187 - val_acc: 0.9936\n",
      "Epoch 3/8\n",
      "22500/22500 [==============================] - 1s 59us/step - loss: 0.0070 - acc: 0.9980 - val_loss: 0.0281 - val_acc: 0.9948\n",
      "Epoch 4/8\n",
      "22500/22500 [==============================] - 1s 55us/step - loss: 0.0046 - acc: 0.9985 - val_loss: 0.0291 - val_acc: 0.9928\n",
      "Epoch 5/8\n",
      "22500/22500 [==============================] - 1s 54us/step - loss: 0.0025 - acc: 0.9994 - val_loss: 0.0280 - val_acc: 0.9940\n",
      "Epoch 6/8\n",
      "22500/22500 [==============================] - 1s 54us/step - loss: 0.0019 - acc: 0.9994 - val_loss: 0.0289 - val_acc: 0.9940\n",
      "Epoch 7/8\n",
      "22500/22500 [==============================] - 1s 54us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0287 - val_acc: 0.9932\n",
      "Epoch 8/8\n",
      "22500/22500 [==============================] - 1s 58us/step - loss: 8.1195e-04 - acc: 0.9997 - val_loss: 0.0354 - val_acc: 0.9936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9acbb98358>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorBoard = TensorBoard(log_dir = './logs')\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=128, \n",
    "          epochs=8, \n",
    "          validation_data=(X_valid, y_valid),\n",
    "          callbacks=[tensorBoard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('Ensemble_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12500/12500 [==============================] - 2s 153us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test, verbose=1)\n",
    "y_pred = y_pred.clip(min=0.005, max=0.995)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12500 images belonging to 1 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label\n",
       "0   1  0.995\n",
       "1   2  0.995\n",
       "2   3  0.995\n",
       "3   4  0.995\n",
       "4   5  0.005\n",
       "5   6  0.005\n",
       "6   7  0.005\n",
       "7   8  0.005\n",
       "8   9  0.005\n",
       "9  10  0.005"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.image import *\n",
    "\n",
    "df = pd.read_csv(\"sample_submission.csv\")\n",
    "\n",
    "image_size = (224, 224)\n",
    "gen = ImageDataGenerator(rotation_range=5, height_shift_range=0.05, horizontal_flip=True,\n",
    "                                 shear_range=0.1, channel_shift_range=10, width_shift_range=0.1)\n",
    "test_generator = gen.flow_from_directory(\"test3\", image_size, shuffle=False, \n",
    "                                         batch_size=10, class_mode=None)\n",
    "\n",
    "for i, fname in enumerate(test_generator.filenames):\n",
    "    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n",
    "    df.set_value(index-1, 'label', y_pred[i])\n",
    "\n",
    "df.to_csv('pred.csv', index=None)\n",
    "df.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
